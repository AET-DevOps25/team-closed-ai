# Ollama LLM configuration
OLLAMA_LLM_HOST=https://gpu.aet.cit.tum.de/ollama

# LLM models to use for different tasks
# These models should be available in your Ollama instance
CLASSIFICATION_MODEL=gemma3:4b
ANSWER_MODEL=llama3.3:latest
TASK_GEN_MODEL=llama3.3:latest

# Ollama embedding configuration
OLLAMA_EMBED_HOST=http://ollama:11434
OLLAMA_EMBED_KEY=none

EMBED_MODEL=nomic-embed-text
EMBED_DIMENSIONS=768

# PostgreSQL database configuration
PG_USER=${DB_USERNAME}
PG_PASSWORD=${DB_PASSWORD}
PG_DB=${DB_NAME}
PG_HOST=postgres
PG_PORT=5432

DATABASE_URL=postgres://${PG_USER}:${PG_PASSWORD}@${PG_HOST}:${PG_PORT}/${PG_DB}

# Ollama vectorizer worker configuration
OLLAMA_HOST=${OLLAMA_EMBED_HOST}
PGAI_VECTORIZER_WORKER_DB_URL=${DATABASE_URL}

TRAEFIK_URL=http://traefik:80
