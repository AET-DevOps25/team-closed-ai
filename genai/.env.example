# Ollama LLM configuration
OLLAMA_LLM_HOST=https://gpu.aet.cit.tum.de/ollama
OLLAMA_LLM_KEY=your-ollama-api-key

# LLM models to use for different tasks
# These models must be available in your Ollama instance
CLASSIFICATION_MODEL=gemma3:4b
ANSWER_MODEL=llama3.3:latest
TASK_GEN_MODEL=llama3.3:latest

# Ollama embedding configuration
OLLAMA_EMBED_HOST=http://ollama:11434
OLLAMA_EMBED_KEY=your-ollama-api-key

EMBED_MODEL=nomic-embed-text
EMBED_DIMENSIONS=768

# PostgreSQL database configuration
PG_USER=postgres
PG_PASSWORD=postgres
PG_DB=closedai
PG_HOST=postgres
PG_PORT=5432

DATABASE_URL=postgres://${PG_USER}:${PG_PASSWORD}@${PG_HOST}:${PG_PORT}/${PG_DB}

# Ollama vectorizer worker configuration
OLLAMA_HOST=${OLLAMA_EMBED_HOST}
PGAI_VECTORIZER_WORKER_DB_URL=${DATABASE_URL}

# Traefik URL for API access
TRAEFIK_URL=http://traefik:80
